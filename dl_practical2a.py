# -*- coding: utf-8 -*-
"""DL_Practical2A.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16HCKTudyl3XWn9fqYxkQN1zuRoOpvBG2
"""

import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder,StandardScaler

url='/content/drive/MyDrive/deep learning/letter-recognition.data'
df=pd.read_csv(url,header=None)

x=df.iloc[:,1:].values
y=df.iloc[:,0].values

le=LabelEncoder()
y=le.fit_transform(y)

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)

scaler=StandardScaler()
X_train = scaler.fit_transform(x_train)
X_test = scaler.transform(x_test)

model=tf.keras.models.Sequential([
    tf.keras.layers.Dense(64, activation='relu',input_shape=[16]),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(26, activation='softmax')
])

model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])

history=model.fit(X_train,y_train,epochs=100,validation_split=0.2)

test_loss,test_acc=model.evaluate(X_test,y_test)

new_x=np.array([[0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0]])
new_x=scaler.transform(new_x)
pred=model.predict(new_x)
print(pred)